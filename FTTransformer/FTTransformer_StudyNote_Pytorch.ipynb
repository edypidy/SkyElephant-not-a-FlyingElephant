{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5Pz6DL4Y9NpQ4s5Fwlmsc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edypidy/SkyElephant-not-a-FlyingElephant/blob/main/FTTransformer/FTTransformer_StudyNote_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "from einops import repeat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omUkWfG2qBnH",
        "outputId": "fc3e017e-aa86-4122-9b53-e2d6db7b85b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 493 kB/s \n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "KHsRPl_S4zuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# numerical embedder\n",
        "\n",
        "class NumericalEmbedder(nn.Module):\n",
        "    def __init__(self, dim, num_numerical_types):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
        "        self.biases = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(-1)\n",
        "        return x * self.weights + self.biases\n",
        "\n",
        "\n",
        "# Feedforward\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gates = x.chunk(2, dim = -1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_mult = 4, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.Layer1 = nn.Sequential(nn.LayerNorm(in_dim),\n",
        "                                    nn.Linear(in_dim, in_dim*hidden_mult*2),\n",
        "                                    GEGLU(),\n",
        "                                    nn.Dropout(dropout))\n",
        "        self.Layer2 = nn.Linear(in_dim*hidden_mult, in_dim)\n",
        "        self.norm = nn.LayerNorm(in_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = self.Layer1(x)\n",
        "        output = self.Layer2(output)\n",
        "        output = self.norm(output)\n",
        "        output = output + x # residual\n",
        "        return output\n",
        "\n",
        "\n",
        "# Attention\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads=8, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.attn(x,x,x)[0]\n",
        "        output = self.norm(output)\n",
        "        output = output + x # residual\n",
        "        return output\n",
        "\n",
        "\n",
        "# Transformer\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embed_dim, depth, num_heads, attn_dropout, ff_dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                SelfAttention(embed_dim, num_heads=num_heads, dropout=attn_dropout),\n",
        "                FeedForward(embed_dim, dropout = ff_dropout),\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x)\n",
        "            x = ff(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "KiVAfRxF3HS_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FTTransformer(nn.Module):\n",
        "    def __init__(self, *,\n",
        "        categories,\n",
        "        num_continuous,\n",
        "        embed_dim = 16,\n",
        "        depth = 2,\n",
        "        heads = 8,\n",
        "        dim_out = 1,\n",
        "        num_special_tokens = 2,\n",
        "        attn_dropout = 0.,\n",
        "        ff_dropout = 0.):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        # Treat Categories\n",
        "\n",
        "        self.num_categories = len(categories)\n",
        "        self.num_unique_categories = sum(categories)\n",
        "\n",
        "        # Create category embeddings table\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens # Since add categories_offset to x_categories, first 'num_special_tokens' special tokens mean NA\n",
        "        total_tokens = self.num_unique_categories + num_special_tokens\n",
        "        # embedding table\n",
        "        self.categorical_embeds = nn.Embedding(total_tokens, embed_dim) # LookUp Table : total_tokens x embed_dim\n",
        "\n",
        "        # offset of categories for the categories embedding table like positional encoding (Alternative methodology from paper)\n",
        "        categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
        "        categories_offset = categories_offset.cumsum(dim = -1)[:-1] # by cumsuming so every category is distinguished\n",
        "        self.register_buffer('categories_offset', categories_offset) # categories offset must be unlearnable\n",
        "\n",
        "\n",
        "        # Treat Continuous\n",
        "\n",
        "        self.numerical_embedder = NumericalEmbedder(embed_dim, num_continuous)\n",
        "        \n",
        "\n",
        "        # cls token\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "\n",
        "\n",
        "        # Transformer\n",
        "\n",
        "        self.transformer = Transformer(embed_dim=embed_dim,\n",
        "                                       depth=depth,\n",
        "                                       num_heads=heads,\n",
        "                                       attn_dropout=attn_dropout,\n",
        "                                       ff_dropout=ff_dropout,\n",
        "                                       )\n",
        "\n",
        "\n",
        "        # To logits\n",
        "\n",
        "        self.to_logits = nn.Sequential(nn.LayerNorm(embed_dim),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(embed_dim, dim_out)\n",
        "                                       )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x_categ, x_numer):\n",
        "        b = x_categ.shape[0] # batch size\n",
        "\n",
        "        assert x_categ.shape[-1] == self.num_categories, f'you must pass in {self.num_categories} values for your categories input'\n",
        "        x_categ += self.categories_offset\n",
        "\n",
        "        x_categ = self.categorical_embeds(x_categ) # Categories Embedding is 'LookUp Table' method => batch x categ_col_nums x embed_dim\n",
        "\n",
        "        # add numerically embedded tokens\n",
        "\n",
        "        x_numer = self.numerical_embedder(x_numer)\n",
        "\n",
        "        # concat categorical and numerical\n",
        "\n",
        "        x = torch.cat((x_categ, x_numer), dim = 1)\n",
        "\n",
        "        # Append cls tokens by batch == torch.cat([self.cls_token for _ in range(b)], dim=0)\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim = 1)\n",
        "\n",
        "        # attend\n",
        "\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # get cls token\n",
        "\n",
        "        x = x[:, 0]\n",
        "\n",
        "        # out in the paper is linear(relu(ln(cls)))\n",
        "\n",
        "        return self.to_logits(x)"
      ],
      "metadata": {
        "id": "CMEVVmX_ebiH"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GEGLU"
      ],
      "metadata": {
        "id": "Cq38ChI44WoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GEGLUE\n",
        "x = torch.randn(5*2)\n",
        "x, gate = x.chunk(2, dim = -1)\n",
        "x * F.gelu(gate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrbxO3Mhgust",
        "outputId": "f57650ff-a820-4e24-aef9-37bcc7991b45"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1978, -0.1254, -0.0500,  0.1201,  0.0209])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Category embedding table & Offset encoding"
      ],
      "metadata": {
        "id": "KJWcBsaT4YLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = (2,3,4,5,6)\n",
        "em = nn.Embedding(sum(categories)+2, 4)\n",
        "em.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXHvsM6gvpBr",
        "outputId": "f9dec498-e498-4f89-c81e-a96dba074647"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1422, -0.0644, -0.2687, -0.3519],\n",
              "        [-0.1310, -0.7452, -0.0613, -0.0983],\n",
              "        [-0.6265,  1.6764,  2.5666,  0.0101],\n",
              "        [ 1.1247, -0.1997, -0.7096, -0.4328],\n",
              "        [-0.7631,  0.0071,  0.1174,  1.2644],\n",
              "        [-0.2029, -0.7141,  1.2456, -1.0946],\n",
              "        [ 0.7132, -0.0879,  0.8890, -0.1016],\n",
              "        [-1.2408,  0.6409, -1.3812,  1.7102],\n",
              "        [ 0.1079,  0.0172, -0.3947,  0.1761],\n",
              "        [ 1.1205, -0.8397,  0.2906,  0.0784],\n",
              "        [-0.3582, -0.1701, -0.2558, -1.2307],\n",
              "        [ 0.0965, -1.2816, -2.9810,  1.9548],\n",
              "        [ 0.1950, -0.0039, -1.6652, -0.2576],\n",
              "        [ 2.2781, -0.7847,  0.7122,  1.2124],\n",
              "        [ 0.8438,  0.3787, -2.6487,  3.0309],\n",
              "        [ 1.2570, -0.1070,  0.6101,  1.7393],\n",
              "        [-0.3522,  1.4458, -0.2538,  1.2323],\n",
              "        [ 1.8391,  1.2671, -0.8121,  1.0957],\n",
              "        [-0.7916, -1.7335, -0.7643,  0.7543],\n",
              "        [ 0.3516,  0.2313,  0.7469,  0.3150],\n",
              "        [-0.2621,  1.8219,  1.4400,  0.9879],\n",
              "        [ 2.8616,  1.8804,  1.7830,  1.1806]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = 2)\n",
        "categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
        "categories_offset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-AVTzPVw6eY",
        "outputId": "aac044f1-6722-4fa5-9e8a-775f94aea39a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  4,  7, 11, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_categ = torch.tensor([[0,2,2,3,5],\n",
        "                        [1,2,3,4,4]])\n",
        "x_categ += categories_offset\n",
        "x_categ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8OcAXUVv4vK",
        "outputId": "0d5928ff-a446-4a1a-eace-7bfadfacedd0"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  6,  9, 14, 21],\n",
              "        [ 3,  6, 10, 15, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_categ = em(x_categ)\n",
        "x_categ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTyRMIMxvvtv",
        "outputId": "06de12fc-14a0-4327-8539-132417982008"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6265,  1.6764,  2.5666,  0.0101],\n",
              "         [ 0.7132, -0.0879,  0.8890, -0.1016],\n",
              "         [ 1.1205, -0.8397,  0.2906,  0.0784],\n",
              "         [ 0.8438,  0.3787, -2.6487,  3.0309],\n",
              "         [ 2.8616,  1.8804,  1.7830,  1.1806]],\n",
              "\n",
              "        [[ 1.1247, -0.1997, -0.7096, -0.4328],\n",
              "         [ 0.7132, -0.0879,  0.8890, -0.1016],\n",
              "         [-0.3582, -0.1701, -0.2558, -1.2307],\n",
              "         [ 1.2570, -0.1070,  0.6101,  1.7393],\n",
              "         [-0.2621,  1.8219,  1.4400,  0.9879]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_categ.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5WudPkIyrwQ",
        "outputId": "687fca94-ccf5-4d82-b28a-56b02895fd3f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical embedding"
      ],
      "metadata": {
        "id": "TXC6lNQs5Eyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nem = NumericalEmbedder(dim=4, num_numerical_types=6)"
      ],
      "metadata": {
        "id": "tpXjGp-p0Cz7"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_numeric = torch.tensor([[1,2,3,4,5,6],\n",
        "                          [7,8,9,10,11,12]])\n",
        "x_numeric = nem(x_numeric)\n",
        "x_numeric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh-MzSdh0dac",
        "outputId": "a7ad5890-4906-4f27-9341-a073070c445b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  3.0601,   0.9302,   0.4125,   0.9413],\n",
              "         [ -3.4176,  -0.5423,   2.9324,  -0.9961],\n",
              "         [ -0.3026,   0.6032,  -2.0968,   0.1400],\n",
              "         [  0.7046,   1.7296,   7.3469,  -4.1400],\n",
              "         [ -0.9279,  -6.4806,  -5.2516,   2.1788],\n",
              "         [  2.8452,  -2.9124,  -2.3786,  -0.4056]],\n",
              "\n",
              "        [[  8.8174,   8.0591,   4.0979,  -3.1194],\n",
              "         [ -8.4295,  -5.6186,  10.4920,  -4.2528],\n",
              "         [ -0.6172,   2.5088,  -4.8487,  -0.9211],\n",
              "         [  0.2880,   4.7461,  20.1742,  -9.9391],\n",
              "         [ -1.9728, -11.7453, -11.0497,   4.9542],\n",
              "         [  7.3594,  -6.0567,  -3.6522,   0.0626]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_numeric.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M8jZolr0uzV",
        "outputId": "7ebbd1ad-7351-4daf-f6a5-b42e2abe2d8f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cat(x_categ, x_numer)"
      ],
      "metadata": {
        "id": "57ahtlkK5jAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.cat((x_categ, x_numeric), dim = 1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiFzT7hp0-pr",
        "outputId": "340215b2-7a52-4a13-bce3-e002145e4b1e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-6.2654e-01,  1.6764e+00,  2.5666e+00,  1.0077e-02],\n",
              "         [ 7.1324e-01, -8.7891e-02,  8.8896e-01, -1.0161e-01],\n",
              "         [ 1.1205e+00, -8.3974e-01,  2.9055e-01,  7.8428e-02],\n",
              "         [ 8.4383e-01,  3.7866e-01, -2.6487e+00,  3.0309e+00],\n",
              "         [ 2.8616e+00,  1.8804e+00,  1.7830e+00,  1.1806e+00],\n",
              "         [ 3.0601e+00,  9.3024e-01,  4.1254e-01,  9.4132e-01],\n",
              "         [-3.4176e+00, -5.4230e-01,  2.9324e+00, -9.9614e-01],\n",
              "         [-3.0264e-01,  6.0320e-01, -2.0968e+00,  1.3997e-01],\n",
              "         [ 7.0458e-01,  1.7296e+00,  7.3469e+00, -4.1400e+00],\n",
              "         [-9.2787e-01, -6.4806e+00, -5.2516e+00,  2.1788e+00],\n",
              "         [ 2.8452e+00, -2.9124e+00, -2.3786e+00, -4.0556e-01]],\n",
              "\n",
              "        [[ 1.1247e+00, -1.9965e-01, -7.0964e-01, -4.3275e-01],\n",
              "         [ 7.1324e-01, -8.7891e-02,  8.8896e-01, -1.0161e-01],\n",
              "         [-3.5822e-01, -1.7007e-01, -2.5581e-01, -1.2307e+00],\n",
              "         [ 1.2570e+00, -1.0699e-01,  6.1011e-01,  1.7393e+00],\n",
              "         [-2.6215e-01,  1.8219e+00,  1.4400e+00,  9.8787e-01],\n",
              "         [ 8.8174e+00,  8.0591e+00,  4.0979e+00, -3.1194e+00],\n",
              "         [-8.4295e+00, -5.6186e+00,  1.0492e+01, -4.2528e+00],\n",
              "         [-6.1717e-01,  2.5088e+00, -4.8487e+00, -9.2110e-01],\n",
              "         [ 2.8803e-01,  4.7461e+00,  2.0174e+01, -9.9391e+00],\n",
              "         [-1.9728e+00, -1.1745e+01, -1.1050e+01,  4.9542e+00],\n",
              "         [ 7.3594e+00, -6.0567e+00, -3.6522e+00,  6.2617e-02]]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cJkFcEp1aPO",
        "outputId": "67f7ac14-61b0-45d8-c358-02bed42e4652"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 11, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cls Tokens"
      ],
      "metadata": {
        "id": "NNVe4BVn5ol2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = 2 # bs\n",
        "cls_token = nn.Parameter(torch.randn(1, 1, 4))\n",
        "cls_tokens = repeat(cls_token, '1 1 d -> b 1 d', b = b)\n",
        "x = torch.cat((cls_tokens, x), dim = 1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zc0vWZL1vHf",
        "outputId": "a0296fe6-63db-42c0-fe9d-6a2aa3d5c1c1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-6.8002e-01, -2.5018e-01,  2.7479e-01,  1.7927e-01],\n",
              "         [-6.2654e-01,  1.6764e+00,  2.5666e+00,  1.0077e-02],\n",
              "         [ 7.1324e-01, -8.7891e-02,  8.8896e-01, -1.0161e-01],\n",
              "         [ 1.1205e+00, -8.3974e-01,  2.9055e-01,  7.8428e-02],\n",
              "         [ 8.4383e-01,  3.7866e-01, -2.6487e+00,  3.0309e+00],\n",
              "         [ 2.8616e+00,  1.8804e+00,  1.7830e+00,  1.1806e+00],\n",
              "         [ 3.0601e+00,  9.3024e-01,  4.1254e-01,  9.4132e-01],\n",
              "         [-3.4176e+00, -5.4230e-01,  2.9324e+00, -9.9614e-01],\n",
              "         [-3.0264e-01,  6.0320e-01, -2.0968e+00,  1.3997e-01],\n",
              "         [ 7.0458e-01,  1.7296e+00,  7.3469e+00, -4.1400e+00],\n",
              "         [-9.2787e-01, -6.4806e+00, -5.2516e+00,  2.1788e+00],\n",
              "         [ 2.8452e+00, -2.9124e+00, -2.3786e+00, -4.0556e-01]],\n",
              "\n",
              "        [[-6.8002e-01, -2.5018e-01,  2.7479e-01,  1.7927e-01],\n",
              "         [ 1.1247e+00, -1.9965e-01, -7.0964e-01, -4.3275e-01],\n",
              "         [ 7.1324e-01, -8.7891e-02,  8.8896e-01, -1.0161e-01],\n",
              "         [-3.5822e-01, -1.7007e-01, -2.5581e-01, -1.2307e+00],\n",
              "         [ 1.2570e+00, -1.0699e-01,  6.1011e-01,  1.7393e+00],\n",
              "         [-2.6215e-01,  1.8219e+00,  1.4400e+00,  9.8787e-01],\n",
              "         [ 8.8174e+00,  8.0591e+00,  4.0979e+00, -3.1194e+00],\n",
              "         [-8.4295e+00, -5.6186e+00,  1.0492e+01, -4.2528e+00],\n",
              "         [-6.1717e-01,  2.5088e+00, -4.8487e+00, -9.2110e-01],\n",
              "         [ 2.8803e-01,  4.7461e+00,  2.0174e+01, -9.9391e+00],\n",
              "         [-1.9728e+00, -1.1745e+01, -1.1050e+01,  4.9542e+00],\n",
              "         [ 7.3594e+00, -6.0567e+00, -3.6522e+00,  6.2617e-02]]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQdX8V6t2BR_",
        "outputId": "9eb42437-505c-45d6-b6eb-d6535f49c640"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "oi7MS1AA5s7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trfm = Transformer(embed_dim=4,\n",
        "                   depth=2,\n",
        "                   num_heads=1,\n",
        "                   attn_dropout=0.,\n",
        "                   ff_dropout=0.,\n",
        "                   )"
      ],
      "metadata": {
        "id": "sRgexE3F2Qjk"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = trfm(x)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uijzdold2Z3B",
        "outputId": "2ed10c44-1512-4fa7-db64-68155ed42915"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.7170e+00,  6.0308e-01, -7.7584e-01, -2.0204e+00],\n",
              "         [-3.1903e-03,  4.8822e+00,  7.0637e-01, -1.9588e+00],\n",
              "         [ 2.5718e+00,  1.6446e+00, -1.7760e-01, -2.6262e+00],\n",
              "         [ 3.5948e+00,  7.6540e-01, -6.5508e-01, -3.0554e+00],\n",
              "         [ 4.3630e+00, -1.5198e+00, -6.1122e-01, -6.2730e-01],\n",
              "         [ 6.7756e+00,  1.8411e+00,  2.1694e+00, -3.0805e+00],\n",
              "         [ 6.6662e+00, -3.9355e-01,  2.1617e+00, -3.0901e+00],\n",
              "         [-1.3417e+00,  1.5901e+00,  1.0613e+00, -3.3334e+00],\n",
              "         [ 3.1904e+00, -1.0991e+00, -4.7316e-01, -3.2745e+00],\n",
              "         [ 3.9085e+00,  3.5467e+00,  4.3235e+00, -6.1377e+00],\n",
              "         [ 1.1349e+00, -5.5581e+00, -5.1775e+00, -8.8057e-01],\n",
              "         [ 5.7184e+00, -2.2019e+00, -2.4690e+00, -3.8989e+00]],\n",
              "\n",
              "        [[ 1.6682e+00,  1.4527e+00, -3.0288e+00, -5.6816e-01],\n",
              "         [ 5.6886e+00, -5.2240e-01, -1.1869e+00, -4.1966e+00],\n",
              "         [ 5.2694e+00, -6.0032e-02,  1.3743e-01, -3.9340e+00],\n",
              "         [ 1.5544e+00,  2.5287e+00, -3.8554e+00, -2.2425e+00],\n",
              "         [ 6.3485e+00, -6.1770e-01,  2.5396e-01, -2.4854e+00],\n",
              "         [ 4.0014e+00, -1.4404e-01,  2.5216e+00, -2.3913e+00],\n",
              "         [ 1.3163e+01,  7.3999e+00,  2.2973e+00, -5.0048e+00],\n",
              "         [-7.3651e+00, -4.8901e+00,  1.0956e+01, -6.5096e+00],\n",
              "         [ 2.7216e+00,  2.0261e+00, -5.9223e+00, -2.7034e+00],\n",
              "         [ 1.4740e+00,  6.1126e+00,  2.0587e+01, -1.2904e+01],\n",
              "         [ 2.5511e+00, -1.2343e+01, -1.0461e+01,  4.3905e-01],\n",
              "         [ 1.2007e+01, -5.5814e+00, -4.5067e+00, -4.2057e+00]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPznzbFt2flE",
        "outputId": "7230ddac-4dd7-45a2-c3da-aa28c4536447"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get cls token"
      ],
      "metadata": {
        "id": "_P27X0Qy5xAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x[:, 0]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZp9jT7b2hkD",
        "outputId": "0c231280-4111-4d97-f4cd-5abb9aa0590f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.7170,  0.6031, -0.7758, -2.0204],\n",
              "        [ 1.6682,  1.4527, -3.0288, -0.5682]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIXdsbx43IT1",
        "outputId": "9c203155-b53b-41a6-c762-6e8fca5ab03d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Logits(Output)"
      ],
      "metadata": {
        "id": "J8KzqaHU55H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim_out=1\n",
        "to_logits = nn.Sequential(nn.LayerNorm(4),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Linear(4, dim_out)\n",
        "                         )"
      ],
      "metadata": {
        "id": "pOydy3jj253C"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = to_logits(x)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZwjaWpy3DhI",
        "outputId": "fa23f439-78d0-4646-9a1a-ddcd80e32f98"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9282],\n",
              "        [-0.8931]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APPENDIX 1 : Self Attention"
      ],
      "metadata": {
        "id": "mmd6RgLR59i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# q : bs x d_L x embed_dim\n",
        "# k : bs x d_s x embed_dim\n",
        "# v : bs x d_s x embed_dim \n",
        "bs = 16\n",
        "embed_dim = 32\n",
        "d_L = 13 # columns\n",
        "d_s = 3 # key columns\n",
        "\n",
        "q = torch.randn(bs, d_L, embed_dim)\n",
        "attn = SelfAttention(embed_dim=32, num_heads=8, dropout=0.)\n",
        "attn(q).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGI2bxWY4dOJ",
        "outputId": "c8289265-9b00-48cf-b11c-8c4578dc3985"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 13, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APPENDIX 2 : Transformer"
      ],
      "metadata": {
        "id": "ogU5pgE16Ewz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = torch.randn(1, 15, embed_dim)\n",
        "trfm = Transformer(embed_dim=embed_dim, depth=3, num_heads=8, attn_dropout=0.1, ff_dropout=0.1)\n",
        "trfm(q).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvy7S51YZcKS",
        "outputId": "eb6ed618-e2ed-40b2-9443-d24b08b18f7c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 15, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 1\n",
        "embed_dim = 32\n",
        "col_dim = 8\n",
        "\n",
        "q = torch.randn(bs, col_dim)\n",
        "nembd = NumericalEmbedder(embed_dim, col_dim)\n",
        "q = nembd(q) # bs x col_dim x embed_dim\n",
        "\n",
        "# Transformer\n",
        "\n",
        "num_heads = 16 # must be : embed_dim%num_heads == 0\n",
        "attn = SelfAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=0.)\n",
        "attn(q).shape # bs x col_dim x embed_dim\n",
        "\n",
        "fdfd = FeedForward(embed_dim, hidden_mult=4, dropout = 0.)\n",
        "fdfd(q).shape # bs x col_dim x embed_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXM03tb5adW1",
        "outputId": "25a86af2-bcc6-438b-9287-3803f67464bf"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APPENDIX 3 : FTTransformer GitHub\n",
        "\n",
        "https://github.com/lucidrains/tab-transformer-pytorch/blob/main/tab_transformer_pytorch/ft_transformer.py"
      ],
      "metadata": {
        "id": "OnH244Q06VLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, einsum\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "# feedforward and attention\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gates = x.chunk(2, dim = -1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "def FeedForward(dim, mult = 4, dropout = 0.):\n",
        "    return nn.Sequential(\n",
        "        nn.LayerNorm(dim),\n",
        "        nn.Linear(dim, dim * mult * 2),\n",
        "        GEGLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(dim * mult, dim)\n",
        "    )\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        heads = 8,\n",
        "        dim_head = 64,\n",
        "        dropout = 0.\n",
        "    ):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.heads\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
        "        q = q * self.scale\n",
        "\n",
        "        sim = einsum('b h i d, b h j d -> b h i j', q, k)\n",
        "\n",
        "        attn = sim.softmax(dim = -1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
        "        return self.to_out(out)\n",
        "\n",
        "# transformer\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        depth,\n",
        "        heads,\n",
        "        dim_head,\n",
        "        attn_dropout,\n",
        "        ff_dropout\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout),\n",
        "                FeedForward(dim, dropout = ff_dropout),\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x) + x\n",
        "            x = ff(x) + x\n",
        "\n",
        "        return x\n",
        "\n",
        "# numerical embedder\n",
        "\n",
        "class NumericalEmbedder(nn.Module):\n",
        "    def __init__(self, dim, num_numerical_types):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
        "        self.biases = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = rearrange(x, 'b n -> b n 1')\n",
        "        return x * self.weights + self.biases\n",
        "\n",
        "# main class\n",
        "\n",
        "class FTTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        categories,\n",
        "        num_continuous,\n",
        "        dim,\n",
        "        depth,\n",
        "        heads,\n",
        "        dim_head = 16,\n",
        "        dim_out = 1,\n",
        "        num_special_tokens = 2,\n",
        "        attn_dropout = 0.,\n",
        "        ff_dropout = 0.\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert all(map(lambda n: n > 0, categories)), 'number of each category must be positive'\n",
        "\n",
        "        # categories related calculations\n",
        "\n",
        "        self.num_categories = len(categories)\n",
        "        self.num_unique_categories = sum(categories)\n",
        "\n",
        "        # create category embeddings table\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens\n",
        "        total_tokens = self.num_unique_categories + num_special_tokens\n",
        "\n",
        "        # for automatically offsetting unique category ids to the correct position in the categories embedding table\n",
        "\n",
        "        categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
        "        categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
        "        self.register_buffer('categories_offset', categories_offset)\n",
        "\n",
        "        # categorical embedding\n",
        "\n",
        "        self.categorical_embeds = nn.Embedding(total_tokens, dim)\n",
        "\n",
        "        # continuous\n",
        "\n",
        "        self.numerical_embedder = NumericalEmbedder(dim, num_continuous)\n",
        "\n",
        "        # cls token\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "\n",
        "        # transformer\n",
        "\n",
        "        self.transformer = Transformer(            \n",
        "            dim = dim,\n",
        "            depth = depth,\n",
        "            heads = heads,\n",
        "            dim_head = dim_head,\n",
        "            attn_dropout = attn_dropout,\n",
        "            ff_dropout = ff_dropout\n",
        "        )\n",
        "\n",
        "        # to logits\n",
        "\n",
        "        self.to_logits = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, dim_out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_categ, x_numer):\n",
        "        b = x_categ.shape[0]\n",
        "\n",
        "        assert x_categ.shape[-1] == self.num_categories, f'you must pass in {self.num_categories} values for your categories input'\n",
        "        x_categ += self.categories_offset\n",
        "\n",
        "        x_categ = self.categorical_embeds(x_categ)\n",
        "\n",
        "        # add numerically embedded tokens\n",
        "\n",
        "        x_numer = self.numerical_embedder(x_numer)\n",
        "\n",
        "        # concat categorical and numerical\n",
        "\n",
        "        x = torch.cat((x_categ, x_numer), dim = 1)\n",
        "\n",
        "        # append cls tokens\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim = 1)\n",
        "\n",
        "        # attend\n",
        "\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # get cls token\n",
        "\n",
        "        x = x[:, 0]\n",
        "\n",
        "        # out in the paper is linear(relu(ln(cls)))\n",
        "\n",
        "        return self.to_logits(x)"
      ],
      "metadata": {
        "id": "w58esSDxbAgO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Do\n",
        "\n",
        "* Why is cls token needed in this model"
      ],
      "metadata": {
        "id": "aiFYSlzJ6wNN"
      }
    }
  ]
}