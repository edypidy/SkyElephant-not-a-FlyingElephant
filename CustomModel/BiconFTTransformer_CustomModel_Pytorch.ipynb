{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhHTjJCy8WWuUwZYC48WR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edypidy/SkyElephant-not-a-FlyingElephant/blob/main/CustomModel/BiconFTTransformer_CustomModel_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "from einops import repeat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omUkWfG2qBnH",
        "outputId": "bbcefdc2-fc86-4165-e71a-0a191ece839d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "KHsRPl_S4zuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# numerical embedder\n",
        "\n",
        "class NumericalEmbedder(nn.Module):\n",
        "    def __init__(self, dim, num_numerical_types):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
        "        self.biases = nn.Parameter(torch.randn(num_numerical_types, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(-1)\n",
        "        return x * self.weights + self.biases\n",
        "\n",
        "\n",
        "# Feedforward\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gates = x.chunk(2, dim = -1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_mult = 4, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.Layer1 = nn.Sequential(nn.LayerNorm(in_dim),\n",
        "                                    nn.Linear(in_dim, in_dim*hidden_mult*2),\n",
        "                                    GEGLU(),\n",
        "                                    nn.Dropout(dropout))\n",
        "        self.Layer2 = nn.Linear(in_dim*hidden_mult, in_dim)\n",
        "        self.norm = nn.LayerNorm(in_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = self.Layer1(x)\n",
        "        output = self.Layer2(output)\n",
        "        output = self.norm(output)\n",
        "        output = output + x # residual\n",
        "        return output\n",
        "\n",
        "\n",
        "# Attention for Binary Conditions\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads=8, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
        "\n",
        "    def forward(self, x, k, v):\n",
        "        output = self.attn(x,k,v)[0]\n",
        "        output = self.norm(output)\n",
        "        output = output + x # residual\n",
        "        return output\n",
        "\n",
        "\n",
        "# Self Attention\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads=8, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.attn(x,x,x)[0]\n",
        "        output = self.norm(output)\n",
        "        output = output + x # residual\n",
        "        return output\n",
        "\n",
        "\n",
        "# Transformer\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embed_dim, depth, num_heads, attn_dropout, ff_dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                SelfAttention(embed_dim, num_heads=num_heads, dropout=attn_dropout),\n",
        "                FeedForward(embed_dim, dropout=ff_dropout),\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x)\n",
        "            x = ff(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "KiVAfRxF3HS_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiconFTTransformer(nn.Module):\n",
        "    def __init__(self, *,\n",
        "        categories,\n",
        "        num_continuous,\n",
        "        num_bicons, # Number of Binary Conditions (Input)\n",
        "        embed_dim = 16,\n",
        "        depth = 2,\n",
        "        heads = 8,\n",
        "        dim_out = 1,\n",
        "        num_special_tokens = 2,\n",
        "        attn_dropout = 0.,\n",
        "        ff_dropout = 0.):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        # Treat Categories\n",
        "\n",
        "        self.num_categories = len(categories)\n",
        "        self.num_unique_categories = sum(categories)\n",
        "\n",
        "        # Create category embeddings table\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens # Since add categories_offset to x_categories, first 'num_special_tokens' special tokens mean NA\n",
        "        total_tokens = self.num_unique_categories + num_special_tokens\n",
        "        # embedding table\n",
        "        self.categorical_embeds = nn.Embedding(total_tokens, embed_dim) # LookUp Table : total_tokens x embed_dim\n",
        "\n",
        "        # offset of categories for the categories embedding table like positional encoding (Alternative methodology from paper)\n",
        "        categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
        "        categories_offset = categories_offset.cumsum(dim = -1)[:-1] # by cumsuming so every category is distinguished\n",
        "        self.register_buffer('categories_offset', categories_offset) # categories offset must be unlearnable\n",
        "\n",
        "\n",
        "        # Treat Continuous\n",
        "\n",
        "        self.numerical_embedder = NumericalEmbedder(embed_dim, num_continuous)\n",
        "        \n",
        "\n",
        "        # Treat Binary Condition\n",
        "\n",
        "        self.bicon_embeds = nn.Embedding(2*num_bicons, embed_dim)\n",
        "        bicon_offset = torch.arange(0,2*num_bicons,2) # every Binary Condition is distinguished\n",
        "        self.register_buffer('bicon_offset', bicon_offset) # bicon offset must be unlearnable\n",
        "\n",
        "\n",
        "        # cls token\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "\n",
        "\n",
        "        # FeedForward & Attention for Bicon\n",
        "\n",
        "        self.feedfoward = FeedForward(in_dim=embed_dim,\n",
        "                                      hidden_mult = 4,\n",
        "                                      dropout = 0.)\n",
        "\n",
        "        self.attention = Attention(embed_dim=embed_dim,\n",
        "                                   num_heads=8,\n",
        "                                   dropout=0.)\n",
        "\n",
        "\n",
        "        # Transformer\n",
        "\n",
        "        self.transformer = Transformer(embed_dim=embed_dim,\n",
        "                                       depth=depth,\n",
        "                                       num_heads=heads,\n",
        "                                       attn_dropout=attn_dropout,\n",
        "                                       ff_dropout=ff_dropout,\n",
        "                                       )\n",
        "\n",
        "\n",
        "        # To logits\n",
        "\n",
        "        self.to_logits = nn.Sequential(nn.LayerNorm(embed_dim),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(embed_dim, dim_out)\n",
        "                                       )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x_categ, x_numer, x_bicon):\n",
        "        b = x_categ.shape[0] # batch size\n",
        "\n",
        "        assert x_categ.shape[-1] == self.num_categories, f'you must pass in {self.num_categories} values for your categories input'\n",
        "        x_categ += self.categories_offset\n",
        "\n",
        "        x_categ = self.categorical_embeds(x_categ) # Categories Embedding is 'LookUp Table' method => batch x categ_col_nums x embed_dim\n",
        "\n",
        "        # add numerically embedded tokens\n",
        "\n",
        "        x_numer = self.numerical_embedder(x_numer)\n",
        "\n",
        "        # concat categorical and numerical\n",
        "\n",
        "        x = torch.cat((x_categ, x_numer), dim = 1)\n",
        "\n",
        "        # Append cls tokens by batch == torch.cat([self.cls_token for _ in range(b)], dim=0)\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
        "        x = torch.cat((cls_tokens, x), dim = 1)\n",
        "\n",
        "        # Tabular transformer\n",
        "\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # bicon\n",
        "\n",
        "        x_bicon += self.bicon_offset\n",
        "        x_bicon = self.bicon_embeds(x_bicon)\n",
        "        x = self.attention(x, x_bicon, x_bicon)\n",
        "        x = self.feedfoward(x)\n",
        "\n",
        "        # get cls token\n",
        "\n",
        "        x = x[:, 0]\n",
        "\n",
        "\n",
        "        return self.to_logits(x)"
      ],
      "metadata": {
        "id": "CMEVVmX_ebiH"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiconFTTransformer(\n",
        "                            categories = (2,3,4,5,6),\n",
        "                            num_continuous = 6,\n",
        "                            num_bicons = 5, # Number of Binary Conditions (Input)\n",
        "                            embed_dim = 16,\n",
        "                            depth = 2,\n",
        "                            heads = 8,\n",
        "                            dim_out = 1,\n",
        "                            num_special_tokens = 2,\n",
        "                            attn_dropout = 0.,\n",
        "                            ff_dropout = 0.,\n",
        "                            )                   "
      ],
      "metadata": {
        "id": "XhY4neOaY3LW"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_categ = torch.tensor([[0,2,2,3,5],\n",
        "                        [1,2,3,4,4]])\n",
        "\n",
        "x_numer = torch.tensor([[1,2,3,4,5,6],\n",
        "                        [7,8,9,10,11,12]])\n",
        "\n",
        "x_bicon = torch.tensor([[1,0,1,1,0],\n",
        "                        [0,1,0,1,1]])"
      ],
      "metadata": {
        "id": "ZdfpK0fiYiDR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(x_categ, x_numer, x_bicon)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScUY-UktZHKt",
        "outputId": "f3972e4f-f1ee-46dc-e50a-aba689948f66"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1343],\n",
              "        [-0.2419]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GEGLU"
      ],
      "metadata": {
        "id": "Cq38ChI44WoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GEGLUE\n",
        "x = torch.randn(5*2)\n",
        "x, gate = x.chunk(2, dim = -1)\n",
        "x * F.gelu(gate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrbxO3Mhgust",
        "outputId": "aa5d13f7-df54-4fd9-9ed9-a917587d42cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0279,  0.0397, -0.6922,  0.1041,  0.0402])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Category embedding table & Offset encoding"
      ],
      "metadata": {
        "id": "KJWcBsaT4YLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = (2,3,4,5,6)\n",
        "em = nn.Embedding(sum(categories)+2, 4)\n",
        "em.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXHvsM6gvpBr",
        "outputId": "87f8925d-7c25-48c3-f9f4-b955a351dbe2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.3067e+00,  1.2984e+00, -1.0242e+00, -1.7189e+00],\n",
              "        [ 6.5156e-01,  6.2607e-01, -1.4641e+00,  8.3954e-01],\n",
              "        [ 4.6663e-01,  1.3844e+00, -1.3162e+00,  1.2584e-01],\n",
              "        [-1.3158e+00, -4.1214e-01,  5.9935e-01,  1.0766e+00],\n",
              "        [-6.8095e-01, -5.2712e-01,  3.7826e-01,  3.9366e-01],\n",
              "        [ 8.1831e-01, -5.4963e-01, -1.7696e+00, -3.1709e-01],\n",
              "        [ 2.5596e-01,  1.3004e+00,  5.5314e-02,  2.1055e-01],\n",
              "        [-1.4878e+00,  7.4846e-01, -1.3628e+00, -7.1766e-01],\n",
              "        [-7.4579e-02,  2.0124e-01,  6.7340e-01,  8.0523e-01],\n",
              "        [-8.3029e-01, -3.1396e-01, -2.5810e-01, -1.2058e-01],\n",
              "        [ 8.4641e-01, -2.5466e+00,  1.3709e+00,  1.9676e+00],\n",
              "        [-7.5616e-01, -6.6290e-01,  7.3224e-01,  1.8029e+00],\n",
              "        [ 1.1537e+00,  1.2258e+00,  1.5889e+00,  3.6194e-01],\n",
              "        [-4.6227e-01,  6.4212e-01,  1.4638e+00, -7.1945e-01],\n",
              "        [-9.2603e-01,  1.0327e+00, -2.1214e-01, -1.8899e+00],\n",
              "        [-8.1364e-01, -2.2753e-01,  1.5726e+00, -4.5318e-01],\n",
              "        [-1.7583e+00,  2.8255e-01,  2.2157e-01, -7.9260e-01],\n",
              "        [ 1.1439e+00,  9.1262e-01, -6.2278e-01, -9.9075e-01],\n",
              "        [-1.0769e+00,  2.2100e+00, -4.7627e-01, -1.0397e+00],\n",
              "        [-1.4757e-01,  2.2300e+00, -4.5033e-01,  7.6208e-01],\n",
              "        [-9.9903e-01, -9.2784e-02,  3.9141e-01,  2.9928e-01],\n",
              "        [ 5.4358e-01,  7.4395e-01,  3.9582e-04, -2.5787e+00]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = 2)\n",
        "categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
        "categories_offset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-AVTzPVw6eY",
        "outputId": "2a1a9f91-0d39-4503-a003-85245cc70a93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  4,  7, 11, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_categ = torch.tensor([[0,2,2,3,5],\n",
        "                        [1,2,3,4,4]])\n",
        "x_categ += categories_offset\n",
        "x_categ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8OcAXUVv4vK",
        "outputId": "44a54b89-c04c-415e-9d6c-a2884adf351a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  6,  9, 14, 21],\n",
              "        [ 3,  6, 10, 15, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_categ = em(x_categ)\n",
        "x_categ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTyRMIMxvvtv",
        "outputId": "4c94e96e-1247-4bad-8f69-4754bccbc4da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 4.6663e-01,  1.3844e+00, -1.3162e+00,  1.2584e-01],\n",
              "         [ 2.5596e-01,  1.3004e+00,  5.5314e-02,  2.1055e-01],\n",
              "         [-8.3029e-01, -3.1396e-01, -2.5810e-01, -1.2058e-01],\n",
              "         [-9.2603e-01,  1.0327e+00, -2.1214e-01, -1.8899e+00],\n",
              "         [ 5.4358e-01,  7.4395e-01,  3.9582e-04, -2.5787e+00]],\n",
              "\n",
              "        [[-1.3158e+00, -4.1214e-01,  5.9935e-01,  1.0766e+00],\n",
              "         [ 2.5596e-01,  1.3004e+00,  5.5314e-02,  2.1055e-01],\n",
              "         [ 8.4641e-01, -2.5466e+00,  1.3709e+00,  1.9676e+00],\n",
              "         [-8.1364e-01, -2.2753e-01,  1.5726e+00, -4.5318e-01],\n",
              "         [-9.9903e-01, -9.2784e-02,  3.9141e-01,  2.9928e-01]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_categ.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5WudPkIyrwQ",
        "outputId": "e506d5d3-ce29-4c02-fa28-347131e8f163"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical embedding"
      ],
      "metadata": {
        "id": "TXC6lNQs5Eyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nem = NumericalEmbedder(dim=4, num_numerical_types=6)"
      ],
      "metadata": {
        "id": "tpXjGp-p0Cz7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_numeric = torch.tensor([[1,2,3,4,5,6],\n",
        "                          [7,8,9,10,11,12]])\n",
        "x_numeric = nem(x_numeric)\n",
        "x_numeric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh-MzSdh0dac",
        "outputId": "7c561b42-6b7b-42d0-f859-846e02981843"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -1.8792,   0.4936,  -0.9040,   0.2564],\n",
              "         [  0.7676,   2.1136,  -2.5433,   4.9248],\n",
              "         [ -1.5781,  -1.3108,  -1.8789,  -3.2565],\n",
              "         [ -0.3217,  -2.3346,   1.2943,  -5.1166],\n",
              "         [ -4.1135,   8.9746,   3.7493,  -4.6333],\n",
              "         [  8.1482,  -5.4053,   1.7416,  -4.0964]],\n",
              "\n",
              "        [[ -2.3383,   3.7103,  -7.4790,   2.6496],\n",
              "         [  0.4137,   9.6544, -11.0666,  17.7024],\n",
              "         [ -4.5528,  -5.2269,  -9.9656, -11.5588],\n",
              "         [ -2.3793,  -5.4869,   1.8560,  -9.6100],\n",
              "         [-11.9771,  18.2670,   7.4803, -10.0707],\n",
              "         [ 16.9347, -11.5030,   3.9160,  -8.8078]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_numeric.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M8jZolr0uzV",
        "outputId": "9f7391ec-533c-4b4d-e168-a51dd9b3787e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cat(x_categ, x_numer)"
      ],
      "metadata": {
        "id": "57ahtlkK5jAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.cat((x_categ, x_numeric), dim = 1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiFzT7hp0-pr",
        "outputId": "0e56b5ed-2a32-4db5-a270-7210f30f2ebe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 4.6663e-01,  1.3844e+00, -1.3162e+00,  1.2584e-01],\n",
              "         [ 2.5596e-01,  1.3004e+00,  5.5314e-02,  2.1055e-01],\n",
              "         [-8.3029e-01, -3.1396e-01, -2.5810e-01, -1.2058e-01],\n",
              "         [-9.2603e-01,  1.0327e+00, -2.1214e-01, -1.8899e+00],\n",
              "         [ 5.4358e-01,  7.4395e-01,  3.9582e-04, -2.5787e+00],\n",
              "         [-1.8792e+00,  4.9361e-01, -9.0405e-01,  2.5636e-01],\n",
              "         [ 7.6763e-01,  2.1136e+00, -2.5433e+00,  4.9248e+00],\n",
              "         [-1.5781e+00, -1.3108e+00, -1.8789e+00, -3.2565e+00],\n",
              "         [-3.2170e-01, -2.3346e+00,  1.2943e+00, -5.1166e+00],\n",
              "         [-4.1135e+00,  8.9746e+00,  3.7493e+00, -4.6333e+00],\n",
              "         [ 8.1482e+00, -5.4053e+00,  1.7416e+00, -4.0964e+00]],\n",
              "\n",
              "        [[-1.3158e+00, -4.1214e-01,  5.9935e-01,  1.0766e+00],\n",
              "         [ 2.5596e-01,  1.3004e+00,  5.5314e-02,  2.1055e-01],\n",
              "         [ 8.4641e-01, -2.5466e+00,  1.3709e+00,  1.9676e+00],\n",
              "         [-8.1364e-01, -2.2753e-01,  1.5726e+00, -4.5318e-01],\n",
              "         [-9.9903e-01, -9.2784e-02,  3.9141e-01,  2.9928e-01],\n",
              "         [-2.3383e+00,  3.7103e+00, -7.4790e+00,  2.6496e+00],\n",
              "         [ 4.1365e-01,  9.6544e+00, -1.1067e+01,  1.7702e+01],\n",
              "         [-4.5528e+00, -5.2269e+00, -9.9656e+00, -1.1559e+01],\n",
              "         [-2.3793e+00, -5.4869e+00,  1.8560e+00, -9.6100e+00],\n",
              "         [-1.1977e+01,  1.8267e+01,  7.4803e+00, -1.0071e+01],\n",
              "         [ 1.6935e+01, -1.1503e+01,  3.9160e+00, -8.8078e+00]]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cJkFcEp1aPO",
        "outputId": "ba423b3f-3284-4ddd-a264-c4ac92c96511"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 11, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cls Tokens"
      ],
      "metadata": {
        "id": "NNVe4BVn5ol2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cls token means target's latent variable\n",
        "b = 2 # bs\n",
        "cls_token = nn.Parameter(torch.randn(1, 1, 4))\n",
        "cls_tokens = repeat(cls_token, '1 1 d -> b 1 d', b = b)\n",
        "x = torch.cat((cls_tokens, x), dim = 1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zc0vWZL1vHf",
        "outputId": "191fbb02-2835-4f46-b23d-c560c1858c7c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.4014e+00,  1.2479e+00,  1.7844e+00,  4.9004e-01],\n",
              "         [ 4.6663e-01,  1.3844e+00, -1.3162e+00,  1.2584e-01],\n",
              "         [ 2.5596e-01,  1.3004e+00,  5.5314e-02,  2.1055e-01],\n",
              "         [-8.3029e-01, -3.1396e-01, -2.5810e-01, -1.2058e-01],\n",
              "         [-9.2603e-01,  1.0327e+00, -2.1214e-01, -1.8899e+00],\n",
              "         [ 5.4358e-01,  7.4395e-01,  3.9582e-04, -2.5787e+00],\n",
              "         [-1.8792e+00,  4.9361e-01, -9.0405e-01,  2.5636e-01],\n",
              "         [ 7.6763e-01,  2.1136e+00, -2.5433e+00,  4.9248e+00],\n",
              "         [-1.5781e+00, -1.3108e+00, -1.8789e+00, -3.2565e+00],\n",
              "         [-3.2170e-01, -2.3346e+00,  1.2943e+00, -5.1166e+00],\n",
              "         [-4.1135e+00,  8.9746e+00,  3.7493e+00, -4.6333e+00],\n",
              "         [ 8.1482e+00, -5.4053e+00,  1.7416e+00, -4.0964e+00]],\n",
              "\n",
              "        [[-1.4014e+00,  1.2479e+00,  1.7844e+00,  4.9004e-01],\n",
              "         [-1.3158e+00, -4.1214e-01,  5.9935e-01,  1.0766e+00],\n",
              "         [ 2.5596e-01,  1.3004e+00,  5.5314e-02,  2.1055e-01],\n",
              "         [ 8.4641e-01, -2.5466e+00,  1.3709e+00,  1.9676e+00],\n",
              "         [-8.1364e-01, -2.2753e-01,  1.5726e+00, -4.5318e-01],\n",
              "         [-9.9903e-01, -9.2784e-02,  3.9141e-01,  2.9928e-01],\n",
              "         [-2.3383e+00,  3.7103e+00, -7.4790e+00,  2.6496e+00],\n",
              "         [ 4.1365e-01,  9.6544e+00, -1.1067e+01,  1.7702e+01],\n",
              "         [-4.5528e+00, -5.2269e+00, -9.9656e+00, -1.1559e+01],\n",
              "         [-2.3793e+00, -5.4869e+00,  1.8560e+00, -9.6100e+00],\n",
              "         [-1.1977e+01,  1.8267e+01,  7.4803e+00, -1.0071e+01],\n",
              "         [ 1.6935e+01, -1.1503e+01,  3.9160e+00, -8.8078e+00]]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQdX8V6t2BR_",
        "outputId": "4705b3e9-f2ad-48b7-c00a-27949a99c03d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "oi7MS1AA5s7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trfm = Transformer(embed_dim=4,\n",
        "                   depth=2,\n",
        "                   num_heads=1,\n",
        "                   attn_dropout=0.,\n",
        "                   ff_dropout=0.,\n",
        "                   )"
      ],
      "metadata": {
        "id": "sRgexE3F2Qjk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = trfm(x)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uijzdold2Z3B",
        "outputId": "c15cc8fd-dc02-4a45-9b23-574fba39df78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -0.7888,   2.6764,   1.2417,  -1.0084],\n",
              "         [  3.7996,  -0.1730,  -1.8198,  -1.1460],\n",
              "         [  2.3503,   1.2890,  -0.0215,  -1.7956],\n",
              "         [  1.8441,  -0.5871,  -1.8705,  -0.9094],\n",
              "         [  1.4295,  -2.1434,  -1.7860,   0.5047],\n",
              "         [  2.5898,  -2.5680,   0.3917,  -1.7043],\n",
              "         [  0.3994,   0.7377,  -3.1928,   0.0224],\n",
              "         [  4.6120,   1.3486,  -3.8567,   3.1588],\n",
              "         [ -1.3121,  -3.9626,  -1.7074,  -1.0421],\n",
              "         [  0.8802,  -2.8357,  -0.2089,  -4.3142],\n",
              "         [ -2.4442,   7.1592,   5.5957,  -6.3336],\n",
              "         [ 11.0505,  -6.6187,   1.6975,  -5.7412]],\n",
              "\n",
              "        [[  0.8180,  -1.1675,   3.1470,  -0.6766],\n",
              "         [  2.0998,  -0.5965,   0.1763,  -1.7317],\n",
              "         [  3.3142,  -0.2662,   0.4821,  -1.7079],\n",
              "         [  2.4479,   0.8118,   0.2092,  -1.8307],\n",
              "         [  1.4139,  -1.1606,   1.9425,  -2.1176],\n",
              "         [  0.3630,  -2.0077,   2.0484,  -0.8048],\n",
              "         [ -1.4120,   2.3614,  -6.8060,   2.3992],\n",
              "         [  3.6653,   9.8020, -12.8649,  16.1015],\n",
              "         [ -1.8201,  -6.2946,  -8.7887, -14.4007],\n",
              "         [ -1.5639,  -5.6802,   0.3062,  -8.6823],\n",
              "         [-10.1919,  15.9376,   9.4535, -11.4998],\n",
              "         [ 19.6880, -12.4149,   3.8160, -10.5493]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPznzbFt2flE",
        "outputId": "bf4cf42e-b2e1-4a70-a2c2-c7729cfb339b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Condition ATTENTION"
      ],
      "metadata": {
        "id": "HuanPN_rDt31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 4\n",
        "bin_size = 5\n",
        "\n",
        "bem = nn.Embedding(2*bin_size, embed_dim)\n",
        "bem.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzdtb6jyBVsd",
        "outputId": "beb76c30-bbe8-462f-bdc2-a52a460f4048"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.0635,  0.8810, -1.7549,  0.2084],\n",
              "        [ 0.7246,  0.1679, -0.7772, -0.7525],\n",
              "        [ 0.1409,  0.5818, -0.9637,  0.2260],\n",
              "        [-0.3102,  0.6790,  0.6046,  0.0792],\n",
              "        [ 0.2471,  0.5555,  1.8950,  0.8578],\n",
              "        [-0.5641,  0.8336,  0.5755, -0.8082],\n",
              "        [-0.4365,  0.2985,  0.9872,  0.4378],\n",
              "        [ 0.1914,  0.0812, -1.0502, -0.7422],\n",
              "        [-0.0071, -0.3820,  1.1363, -0.9915],\n",
              "        [ 0.5141,  0.3512,  0.1439,  1.1197]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bin_condition_tensor = torch.tensor([[1,0,1,1,0],\n",
        "                                     [0,1,0,1,1]])\n",
        "bin_offset = torch.arange(0,2*bin_size,2)\n",
        "bin_condition_tensor += bin_offset\n",
        "bin_k = bem(bin_condition_tensor)\n",
        "\n",
        "bin_v = bin_k\n",
        "bin_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqYqDSK4CFwt",
        "outputId": "de2551a3-6239-4c18-d287-61215ab42287"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7246,  0.1679, -0.7772, -0.7525],\n",
              "         [ 0.1409,  0.5818, -0.9637,  0.2260],\n",
              "         [-0.5641,  0.8336,  0.5755, -0.8082],\n",
              "         [ 0.1914,  0.0812, -1.0502, -0.7422],\n",
              "         [-0.0071, -0.3820,  1.1363, -0.9915]],\n",
              "\n",
              "        [[-1.0635,  0.8810, -1.7549,  0.2084],\n",
              "         [-0.3102,  0.6790,  0.6046,  0.0792],\n",
              "         [ 0.2471,  0.5555,  1.8950,  0.8578],\n",
              "         [ 0.1914,  0.0812, -1.0502, -0.7422],\n",
              "         [ 0.5141,  0.3512,  0.1439,  1.1197]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bcattn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=2, dropout=0., batch_first=True)\n",
        "x = bcattn(x, bin_k, bin_v)[0]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neWr3vgxMaoz",
        "outputId": "1a009a16-c796-400f-8daf-7a1e3126476b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 4.6725e-01, -1.6088e-01, -1.8428e-01,  1.3721e-01],\n",
              "         [ 2.6983e-01, -1.4563e-01, -2.1253e-01, -3.9766e-02],\n",
              "         [ 4.4512e-01, -2.0049e-01, -2.6601e-01,  7.0584e-03],\n",
              "         [ 8.0603e-02, -5.0830e-02, -7.4027e-02, -6.6657e-03],\n",
              "         [-5.2986e-02,  9.8208e-03,  1.2880e-02, -7.9237e-03],\n",
              "         [ 3.4141e-01, -1.5935e-01, -2.1669e-01,  5.0772e-03],\n",
              "         [-9.1156e-02,  2.8843e-02,  4.2193e-02, -4.9003e-03],\n",
              "         [-2.8066e-02, -2.7779e-02, -6.2709e-02, -7.9504e-02],\n",
              "         [-1.2866e-01,  6.4153e-02,  1.0513e-01,  4.1912e-02],\n",
              "         [ 2.5326e-01, -1.1290e-01, -1.5010e-01,  3.2531e-02],\n",
              "         [ 7.1787e-01, -2.2565e-01, -2.3679e-01,  2.2749e-01],\n",
              "         [ 4.7098e-01, -2.4602e-01, -3.4683e-01, -1.0469e-01]],\n",
              "\n",
              "        [[ 3.7504e-02, -8.9181e-02, -1.6738e-01, -3.9273e-01],\n",
              "         [ 6.8236e-03, -6.3006e-02, -4.3001e-02, -2.3421e-01],\n",
              "         [ 8.8369e-02, -9.7678e-02, -4.6880e-02, -2.7342e-01],\n",
              "         [ 7.5746e-02, -8.8275e-02, -5.5150e-02, -2.6517e-01],\n",
              "         [ 6.1002e-02, -8.2923e-02, -1.1658e-01, -3.0817e-01],\n",
              "         [-5.9560e-02, -4.5888e-02, -1.2297e-01, -3.0948e-01],\n",
              "         [-5.6375e-01,  1.1615e-01, -1.8323e-03,  9.3050e-02],\n",
              "         [-5.7154e-01,  1.1608e-01,  9.7826e-05,  9.1701e-02],\n",
              "         [-5.7048e-01,  1.1669e-01, -1.2317e-03,  9.7733e-02],\n",
              "         [-3.4433e-01,  6.9267e-02, -7.3783e-02, -2.2395e-02],\n",
              "         [ 6.3677e-02, -1.3471e-01, -2.7678e-01, -6.0930e-01],\n",
              "         [ 2.0532e-01, -1.5535e-01, -4.2161e-02, -3.7731e-01]]],\n",
              "       grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE-t7CCMNnn1",
        "outputId": "49c0afc0-8070-417d-b9b9-a9c7db5a1809"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## feedfoward"
      ],
      "metadata": {
        "id": "vtuZMMH4O9No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fdfd = FeedForward(in_dim=embed_dim)\n",
        "x = fdfd(x)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAKdKR_zOqwC",
        "outputId": "94a9f3b6-ab93-4520-cd51-508e4aa6c0bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.2004, -0.0074,  0.4194,  1.0477],\n",
              "         [-1.2976, -0.2404,  0.3447,  1.0652],\n",
              "         [-1.1598, -0.2166,  0.3126,  1.0496],\n",
              "         [-1.5231, -0.0636,  0.4903,  1.0455],\n",
              "         [-1.0616,  1.1393,  0.8740, -0.9899],\n",
              "         [-1.2654, -0.1694,  0.3590,  1.0463],\n",
              "         [-1.1129,  1.1745,  0.8843, -0.9709],\n",
              "         [-0.9264, -0.9203,  0.2057,  1.4429],\n",
              "         [-1.2527,  1.1561,  0.9995, -0.8203],\n",
              "         [-1.3827, -0.0493,  0.4347,  1.0201],\n",
              "         [-0.9534, -0.0618,  0.3724,  1.1257],\n",
              "         [-1.0659, -0.4066,  0.2115,  1.0345]],\n",
              "\n",
              "        [[-0.4282, -1.2404, -0.1149,  1.1718],\n",
              "         [ 0.2498, -1.6024,  0.0045,  1.0147],\n",
              "         [ 0.2840, -1.7548,  0.4178,  0.7234],\n",
              "         [ 0.1985, -1.7062,  0.3438,  0.8310],\n",
              "         [-0.2567, -1.4072,  0.0759,  1.1413],\n",
              "         [-0.7325, -0.5967, -0.6253,  1.4166],\n",
              "         [-1.6178,  1.0785,  1.0334, -0.8505],\n",
              "         [-1.6273,  1.0800,  1.0337, -0.8501],\n",
              "         [-1.6277,  1.0790,  1.0339, -0.8425],\n",
              "         [-1.2244,  0.9735,  1.0110, -1.1314],\n",
              "         [-0.4655, -1.2444, -0.2118,  0.9646],\n",
              "         [ 0.3587, -1.8248,  0.5844,  0.5122]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get cls token"
      ],
      "metadata": {
        "id": "_P27X0Qy5xAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x[:, 0]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZp9jT7b2hkD",
        "outputId": "96ba0c6b-300b-4ed7-ac6a-ae128be2cc93"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2004, -0.0074,  0.4194,  1.0477],\n",
              "        [-0.4282, -1.2404, -0.1149,  1.1718]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIXdsbx43IT1",
        "outputId": "ab212d00-dca6-47da-ccd7-4bcb560f31af"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Logits(Output)"
      ],
      "metadata": {
        "id": "J8KzqaHU55H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim_out=1\n",
        "to_logits = nn.Sequential(nn.LayerNorm(4),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Linear(4, dim_out)\n",
        "                         )"
      ],
      "metadata": {
        "id": "pOydy3jj253C"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = to_logits(x)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZwjaWpy3DhI",
        "outputId": "00674e90-59d0-4507-c35f-2810964373b1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3770],\n",
              "        [0.5120]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = torch.tensor([[1.],\n",
        "                      [0.]])\n",
        "label = label"
      ],
      "metadata": {
        "id": "o_W-rXDpPOOM"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsZ6Ar_ARWdN",
        "outputId": "f548dd54-8537-4df2-b1a9-5f796ebfb7f5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3770],\n",
              "        [0.5120]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFmuEIR2RX9P",
        "outputId": "5b80c1e1-f754-48b7-af49-7f0d743f7568"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "KfDTqVRhPKrX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn(output, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyH-TEjdPXf3",
        "outputId": "17f38284-2d46-4764-fe58-18e1c7c32ebb"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7519, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APPENDIX 1 : Self Attention"
      ],
      "metadata": {
        "id": "mmd6RgLR59i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# q : bs x d_L x embed_dim\n",
        "# k : bs x d_s x embed_dim\n",
        "# v : bs x d_s x embed_dim \n",
        "bs = 2\n",
        "embed_dim = 4\n",
        "d_L = 12 # columns\n",
        "d_s = 5 # key columns\n",
        "\n",
        "x = torch.randn(bs, d_L, embed_dim)\n",
        "attn = SelfAttention(embed_dim=embed_dim, num_heads=2, dropout=0.)\n",
        "x = attn(x)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGI2bxWY4dOJ",
        "outputId": "09a7fb1a-85d6-4fd0-dc81-6ebd97f7ebf1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0579,  0.0130, -0.7549,  0.5313],\n",
              "         [ 0.7225,  0.6496, -1.9422,  0.8639],\n",
              "         [-0.1123, -0.6458, -1.5604,  0.9912],\n",
              "         [ 1.2144,  0.1313,  1.0603, -0.8106],\n",
              "         [ 0.4380,  0.1359,  1.4092, -1.1720],\n",
              "         [-1.7602, -1.0861, -0.4067,  0.2237],\n",
              "         [ 0.0419, -0.0641,  0.1427, -0.1083],\n",
              "         [-0.7174, -0.1175, -0.4785,  0.0666],\n",
              "         [ 1.5394,  1.0056, -0.9245,  0.8754],\n",
              "         [ 0.4132,  0.5687,  0.4832, -0.8695],\n",
              "         [-0.2170,  0.3749,  1.6618, -0.9050],\n",
              "         [ 0.3322, -1.4531,  1.6286, -0.6463]],\n",
              "\n",
              "        [[ 0.1636, -0.0983,  0.4336, -2.2646],\n",
              "         [ 1.3706,  0.7240, -1.0046, -1.0719],\n",
              "         [ 1.5137,  1.8197,  0.0781, -1.5781],\n",
              "         [ 0.3187, -1.1351, -1.2591,  0.0212],\n",
              "         [ 0.2089,  1.5636,  0.8218, -2.4446],\n",
              "         [-0.2044,  0.1289,  0.1894, -1.5802],\n",
              "         [ 1.9724,  1.1960,  1.0150, -1.2885],\n",
              "         [-0.4001, -0.4109,  0.6811, -3.2625],\n",
              "         [ 0.9830, -0.1506,  1.8850, -2.2997],\n",
              "         [ 0.4828,  1.3002,  2.0218, -0.0445],\n",
              "         [ 0.0260,  0.0367,  1.5599, -3.2120],\n",
              "         [ 0.5649,  0.8877,  0.8670, -2.2798]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZHdZGt5K8Vx",
        "outputId": "b0fa07aa-1233-4824-932e-5ef0c27ce9aa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdfd = FeedForward(in_dim=embed_dim)\n",
        "x = fdfd(x)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3bxFx96LDKi",
        "outputId": "4ab6b7e5-f90c-42f1-965c-203856ce8dff"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0191,  0.2112, -2.2198,  1.8751],\n",
              "         [ 0.2210,  1.8677, -3.3013,  1.5063],\n",
              "         [ 0.3734, -1.0315, -2.9535,  2.2842],\n",
              "         [-0.2879,  1.1304,  1.8668, -1.1138],\n",
              "         [-1.0593,  0.8167,  2.5105, -1.4567],\n",
              "         [-0.7525, -1.1819, -1.9925,  0.8977],\n",
              "         [-1.0067,  0.7492,  1.3117, -1.0420],\n",
              "         [ 0.4734, -1.1125, -1.4627,  0.8550],\n",
              "         [ 1.4386,  2.2276, -2.4494,  1.2791],\n",
              "         [-1.0966,  1.6847,  0.2358, -0.2282],\n",
              "         [-1.6550,  0.8717,  2.9204, -1.2225],\n",
              "         [-0.0924, -0.5290,  2.5706, -2.0877]],\n",
              "\n",
              "        [[-1.5330,  0.7939,  0.8502, -1.8769],\n",
              "         [ 1.9390,  1.5469, -2.7069, -0.7610],\n",
              "         [ 1.7843,  2.9085, -1.5542, -1.3051],\n",
              "         [ 1.5474, -2.2210, -2.1354,  0.7546],\n",
              "         [-1.1386,  2.9425,  0.4342, -2.0884],\n",
              "         [-1.8980,  1.0335,  0.5967, -1.1986],\n",
              "         [ 0.7988,  2.1834,  0.2061, -0.2935],\n",
              "         [-2.0653,  0.3151,  1.5099, -3.1521],\n",
              "         [-0.5341,  0.6537,  2.8725, -2.5745],\n",
              "         [-0.9618,  1.7201,  3.3124, -0.3105],\n",
              "         [-1.6059,  0.7188,  2.4927, -3.1950],\n",
              "         [-1.0435,  1.9265,  0.8610, -1.7041]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOpEL9qELfKd",
        "outputId": "75a6e08d-f098-413f-d837-d86056e35b92"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APPENDIX 2 : Transformer"
      ],
      "metadata": {
        "id": "ogU5pgE16Ewz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = torch.randn(1, 15, embed_dim)\n",
        "trfm = Transformer(embed_dim=embed_dim, depth=3, num_heads=8, attn_dropout=0.1, ff_dropout=0.1)\n",
        "trfm(q).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvy7S51YZcKS",
        "outputId": "eb6ed618-e2ed-40b2-9443-d24b08b18f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 15, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 1\n",
        "embed_dim = 32\n",
        "col_dim = 8\n",
        "\n",
        "q = torch.randn(bs, col_dim)\n",
        "nembd = NumericalEmbedder(embed_dim, col_dim)\n",
        "q = nembd(q) # bs x col_dim x embed_dim\n",
        "\n",
        "# Transformer\n",
        "\n",
        "num_heads = 16 # must be : embed_dim%num_heads == 0\n",
        "attn = SelfAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=0.)\n",
        "attn(q).shape # bs x col_dim x embed_dim\n",
        "\n",
        "fdfd = FeedForward(embed_dim, hidden_mult=4, dropout = 0.)\n",
        "fdfd(q).shape # bs x col_dim x embed_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXM03tb5adW1",
        "outputId": "25a86af2-bcc6-438b-9287-3803f67464bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    }
  ]
}